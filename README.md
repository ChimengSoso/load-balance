
<h1 id="firstHeading" class="firstHeading" lang="en">Load balancing (computing)</h1>

<p>In <a href="/wiki/Computing" title="Computing">computing</a>, <b>load balancing</b> refers to the process of distributing a set of <a href="/wiki/Task_(computing)" title="Task (computing)">tasks</a> over a set of <a href="/wiki/System_resource" title="System resource">resources</a> (computing units), with the aim of making their overall processing more efficient. Load balancing techniques can optimize the response time for each task, avoiding unevenly overloading compute nodes while other compute nodes are left idle.
</p><p>Load balancing is the subject of research in the field of <a href="/wiki/Parallel_computers" class="mw-redirect" title="Parallel computers">parallel computers</a>. Two main approaches exist: static algorithms, which do not take into account the state of the different machines, and dynamic algorithms, which are usually more general and more efficient, but require exchanges of information between the different computing units, at the risk of a loss of efficiency.   
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Problem_Overview"><span class="tocnumber">1</span> <span class="toctext">Problem Overview</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Nature_of_tasks"><span class="tocnumber">1.1</span> <span class="toctext">Nature of tasks</span></a>
<ul>
<li class="toclevel-3 tocsection-3"><a href="#Size_of_tasks"><span class="tocnumber">1.1.1</span> <span class="toctext">Size of tasks</span></a></li>
<li class="toclevel-3 tocsection-4"><a href="#Dependencies"><span class="tocnumber">1.1.2</span> <span class="toctext">Dependencies</span></a></li>
<li class="toclevel-3 tocsection-5"><a href="#Segregation_of_tasks"><span class="tocnumber">1.1.3</span> <span class="toctext">Segregation of tasks</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-6"><a href="#Static_and_dynamic_algorithms"><span class="tocnumber">1.2</span> <span class="toctext">Static and dynamic algorithms</span></a>
<ul>
<li class="toclevel-3 tocsection-7"><a href="#Static"><span class="tocnumber">1.2.1</span> <span class="toctext">Static</span></a></li>
<li class="toclevel-3 tocsection-8"><a href="#Dynamic"><span class="tocnumber">1.2.2</span> <span class="toctext">Dynamic</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-9"><a href="#Hardware_architecture"><span class="tocnumber">1.3</span> <span class="toctext">Hardware architecture</span></a>
<ul>
<li class="toclevel-3 tocsection-10"><a href="#Heterogenous_machines"><span class="tocnumber">1.3.1</span> <span class="toctext">Heterogenous machines</span></a></li>
<li class="toclevel-3 tocsection-11"><a href="#Shared_and_distributed_memory"><span class="tocnumber">1.3.2</span> <span class="toctext">Shared and distributed memory</span></a></li>
<li class="toclevel-3 tocsection-12"><a href="#Hierarchy"><span class="tocnumber">1.3.3</span> <span class="toctext">Hierarchy</span></a></li>
<li class="toclevel-3 tocsection-13"><a href="#Adaptation_to_larger_architectures_(scalability)"><span class="tocnumber">1.3.4</span> <span class="toctext">Adaptation to larger architectures (scalability)</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-14"><a href="#Fault_tolerance"><span class="tocnumber">1.4</span> <span class="toctext">Fault tolerance</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-15"><a href="#Approaches"><span class="tocnumber">2</span> <span class="toctext">Approaches</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Static_distribution_with_full_knowledge_of_the_tasks:_prefix_sum"><span class="tocnumber">2.1</span> <span class="toctext">Static distribution with full knowledge of the tasks: prefix sum</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Static_load_distribution_without_prior_knowledge"><span class="tocnumber">2.2</span> <span class="toctext">Static load distribution without prior knowledge</span></a>
<ul>
<li class="toclevel-3 tocsection-18"><a href="#Round-Robin"><span class="tocnumber">2.2.1</span> <span class="toctext">Round-Robin</span></a></li>
<li class="toclevel-3 tocsection-19"><a href="#Randomized_static"><span class="tocnumber">2.2.2</span> <span class="toctext">Randomized static</span></a></li>
<li class="toclevel-3 tocsection-20"><a href="#Others"><span class="tocnumber">2.2.3</span> <span class="toctext">Others</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-21"><a href="#Master-Worker_Scheme"><span class="tocnumber">2.3</span> <span class="toctext">Master-Worker Scheme</span></a></li>
<li class="toclevel-2 tocsection-22"><a href="#Non-hierarchical_architecture,_without_knowledge_of_the_system:_work_stealing"><span class="tocnumber">2.4</span> <span class="toctext">Non-hierarchical architecture, without knowledge of the system: work stealing</span></a>
<ul>
<li class="toclevel-3 tocsection-23"><a href="#Principle"><span class="tocnumber">2.4.1</span> <span class="toctext">Principle</span></a></li>
<li class="toclevel-3 tocsection-24"><a href="#Efficiency"><span class="tocnumber">2.4.2</span> <span class="toctext">Efficiency</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-25"><a href="#Application"><span class="tocnumber">3</span> <span class="toctext">Application</span></a>
<ul>
<li class="toclevel-2 tocsection-26"><a href="#Internet-based_services"><span class="tocnumber">3.1</span> <span class="toctext">Internet-based services</span></a>
<ul>
<li class="toclevel-3 tocsection-27"><a href="#Round-robin_DNS"><span class="tocnumber">3.1.1</span> <span class="toctext">Round-robin DNS</span></a></li>
<li class="toclevel-3 tocsection-28"><a href="#DNS_delegation"><span class="tocnumber">3.1.2</span> <span class="toctext">DNS delegation</span></a></li>
<li class="toclevel-3 tocsection-29"><a href="#Client-side_random_load_balancing"><span class="tocnumber">3.1.3</span> <span class="toctext">Client-side random load balancing</span></a></li>
<li class="toclevel-3 tocsection-30"><a href="#Server-side_load_balancers"><span class="tocnumber">3.1.4</span> <span class="toctext">Server-side load balancers</span></a>
<ul>
<li class="toclevel-4 tocsection-31"><a href="#Scheduling_algorithms"><span class="tocnumber">3.1.4.1</span> <span class="toctext">Scheduling algorithms</span></a></li>
<li class="toclevel-4 tocsection-32"><a href="#Persistence"><span class="tocnumber">3.1.4.2</span> <span class="toctext">Persistence</span></a></li>
<li class="toclevel-4 tocsection-33"><a href="#Load_balancer_features"><span class="tocnumber">3.1.4.3</span> <span class="toctext">Load balancer features</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-2 tocsection-34"><a href="#Use_in_telecommunications"><span class="tocnumber">3.2</span> <span class="toctext">Use in telecommunications</span></a>
<ul>
<li class="toclevel-3 tocsection-35"><a href="#Shortest_Path_Bridging"><span class="tocnumber">3.2.1</span> <span class="toctext">Shortest Path Bridging</span></a></li>
<li class="toclevel-3 tocsection-36"><a href="#Routing_1"><span class="tocnumber">3.2.2</span> <span class="toctext">Routing 1</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-37"><a href="#Use_in_datacenter_networks"><span class="tocnumber">3.3</span> <span class="toctext">Use in datacenter networks</span></a></li>
<li class="toclevel-2 tocsection-38"><a href="#Relationship_to_failovers"><span class="tocnumber">3.4</span> <span class="toctext">Relationship to failovers</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-39"><a href="#See_also"><span class="tocnumber">4</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-40"><a href="#References"><span class="tocnumber">5</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-41"><a href="#External_links"><span class="tocnumber">6</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Problem_Overview">Problem Overview</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=1" title="Edit section: Problem Overview">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A load balancing algorithm always tries to answer a specific problem. Among other things, the nature of the tasks, the algorithmic <a href="/wiki/Computational_complexity" title="Computational complexity">complexity</a>, the hardware architecture on which the algorithms will run as well as required <a href="/wiki/Error_tolerance" class="mw-redirect" title="Error tolerance">error tolerance</a>, must be taken into account. Therefore compromise must be found to best meet application-specific requirements. 
</p>
<h3><span class="mw-headline" id="Nature_of_tasks">Nature of tasks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=2" title="Edit section: Nature of tasks">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The efficiency of load balancing algorithms critically depends on the nature of the tasks. Therefore, the more information about the tasks is available at the time of decision making, the greater the potential for optimization. 
</p>
<h4><span class="mw-headline" id="Size_of_tasks">Size of tasks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=3" title="Edit section: Size of tasks">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>A perfect knowledge of the <a href="/wiki/Execution_time" class="mw-redirect" title="Execution time">execution time</a> of each of the tasks allows to reach an optimal load distribution (see algorithm of <a href="/wiki/Prefix_sum" title="Prefix sum">prefix sum</a>).<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup> Unfortunately, this is in fact an idealized case. Knowing the exact <a href="/wiki/Execution_time" class="mw-redirect" title="Execution time">execution time</a> of each task is an extremely rare situation.  
</p><p>For this reason, there are several techniques to get an idea of the different execution times. First of all, in the fortunate scenario of having tasks of relatively homogeneous size, it is possible to consider that each of them will require approximately the average execution time. If, on the other hand, the execution time is very irregular, more sophisticated techniques must be used. One technique is to add some <a href="/wiki/Metadata" title="Metadata">metadata</a> to each task. Depending on the previous execution time for similar metadata, it is possible to make inferences for a future task based on statistics.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup> 
</p>
<h4><span class="mw-headline" id="Dependencies">Dependencies</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=4" title="Edit section: Dependencies">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In some cases, tasks depend on each other. These interdependencies can be illustrated by a <a href="/wiki/Directed_acyclic_graph" title="Directed acyclic graph">directed acyclic graph</a>. Intuitively, some tasks cannot begin until others are completed. 
</p><p>Assuming that the required time for each of the tasks is known in advance, an optimal execution order must lead to the minimization of the total execution time. Although this is an <a href="/wiki/NP-hard" class="mw-redirect" title="NP-hard">NP-hard</a> problem and therefore can be difficult to be solved exactly. There are algorithms, like <a href="/wiki/Job_scheduler" title="Job scheduler">job scheduler</a>, that calculate optimal task distributions using <a href="/wiki/Metaheuristic" title="Metaheuristic">metaheuristic</a> methods.
</p>
<h4><span class="mw-headline" id="Segregation_of_tasks">Segregation of tasks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=5" title="Edit section: Segregation of tasks">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Another feature of the tasks critical for the design of a load balancing algorithm is their ability to be broken down into subtasks during execution. The "Tree-Shaped Computation" algorithm presented later takes great advantage of this specificity. 
</p>
<h3><span class="mw-headline" id="Static_and_dynamic_algorithms">Static and dynamic algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=6" title="Edit section: Static and dynamic algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span class="mw-headline" id="Static">Static</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=7" title="Edit section: Static">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>A load balancing algorithm is "static" when it does not take into account the state of the system for the distribution of tasks. Thereby, the system state includes measures such as the <a href="/wiki/Load_(computing)" title="Load (computing)">load level</a> (and sometimes even overload) of certain processors. Instead, assumptions on the overall system are made beforehand, such as the arrival times and resource requirements of incoming tasks. In addition, the number of processors, their respective power and communication speeds are known. Therefore, static load balancing aims to associate a known set of tasks with the available processors in order to minimize a certain performance function. The trick lies in the concept of this performance function. 
</p><p>Static load balancing techniques are commonly centralized around a router, or <a href="/wiki/Master/slave_(technology)" title="Master/slave (technology)">Master</a>, which distributes the loads and optimizes the performance function. This minimization can take into account information related to the tasks to be distributed, and derive an expected execution time.  
</p><p>The advantage of static algorithms is that they are easy to set up and extremely efficient in the case of fairly regular tasks (such as processing HTTP requests from a website). However, there is still some statistical variance in the assignment of tasks which can lead to overloading of some computing units.
</p>
<h4><span class="mw-headline" id="Dynamic">Dynamic</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=8" title="Edit section: Dynamic">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Unlike static load distribution algorithms, dynamic algorithms take into account the current load of each of the computing units (also called nodes) in the system. In this approach, tasks can be moved dynamically from an overloaded node to an underloaded node in order to receive faster processing. While these algorithms are much more complicated to design, they can produce excellent results, in particular, when the execution time varies greatly from one task to another. 
</p><p>In dynamic load balancing the architecture can be more <a href="/wiki/Modular" class="mw-redirect" title="Modular">modular</a> since it is not mandatory to have a specific node dedicated to the distribution of work. When tasks are uniquely assigned to a processor according to its state at a given moment, it is unique assignment. If, on the other hand, the tasks can be permanently redistributed according to the state of the system and its evolution, this is called dynamic assignment <sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup>. Obviously, a load balancing algorithm that requires too much communication in order to reach its decisions runs the risk of slowing down the resolution of the overall problem.
</p>
<h3><span class="mw-headline" id="Hardware_architecture">Hardware architecture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=9" title="Edit section: Hardware architecture">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span class="mw-headline" id="Heterogenous_machines">Heterogenous machines</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=10" title="Edit section: Heterogenous machines">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Parallel computing infrastructures are often composed of units of different <a href="/wiki/Computing_power" class="mw-redirect" title="Computing power">computing power</a>, which should be taken into account for the load distribution. 
</p><p>For example, lower-powered units may receive requests that require a smaller amount of computation, or, in the case of homogeneous or unknown request sizes, receive fewer requests than larger units.   
</p>
<h4><span class="mw-headline" id="Shared_and_distributed_memory">Shared and distributed memory</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=11" title="Edit section: Shared and distributed memory">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Parallel computers are often divided into two broad categories: those where all processors share a single common memory on which they read and write in parallel (<a href="/wiki/Parallel_random-access_machine" title="Parallel random-access machine">PRAM</a> model), and those where each computing unit has its own memory (<a href="/wiki/Distributed_memory" title="Distributed memory">distributed memory</a> model), and where information is exchanged by messages. 
</p><p>For <a href="/wiki/Shared-memory" class="mw-redirect" title="Shared-memory">shared-memory</a> computers, managing write conflicts greatly slows down the speed of individual execution of each computing unit. However, they can work perfectly well in parallel. Conversely, in the case of message exchange, each of the processors can work at full speed. On the other hand, when it comes to collective message exchange, all processors are forced to wait for the slowest processors to start the communication phase.
</p><p>In reality, few systems fall into exactly one of the categories. In general, the processors each have an internal memory to store the data needed for the next calculations, and are organized in successive <a href="/wiki/Computer_cluster" title="Computer cluster">clusters</a>. Often, these processing elements are then coordinated through distributed memory and message passing. Therefore, the load balancing algorithm should be uniquely adapted to a parallel architecture. Otherwise, there is a risk that the efficiency of parallel problem solving will be greatly reduced. 
</p>
<h4><span class="mw-headline" id="Hierarchy">Hierarchy</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=12" title="Edit section: Hierarchy">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Adapting to the hardware structures seen above, there are two main categories of load balancing algorithms. On the one hand, the one where tasks are assigned by “master” and executed by “workers” who keep the master informed of the progress of their work, and the master can then take charge of assigning or reassigning the workload in case of dynamic algorithm. The literature refers to this as <a href="/wiki/Master/slave_(technology)" title="Master/slave (technology)">"Master-Worker"</a> architecture. On the other hand, the control can be distributed between the different nodes. The load balancing algorithm is then executed on each of them and the responsibility for assigning tasks (as well as re-assigning and splitting as appropriate) is shared. The last category assumes a dynamic load balancing algorithm. 
</p><p>Since the design of each load balancing algorithm is unique, the previous distinction must be qualified. Thus, it is also possible to have an intermediate strategy, with, for example, "master" nodes for each sub-cluster, which are themselves subject to a global "master". There are also multi-level organizations, with an alternation between master-slave and distributed control strategies. The latter strategies quickly become complex and are rarely encountered. Designers prefer algorithms that are easier to control. 
</p>
<h4><span id="Adaptation_to_larger_architectures_.28scalability.29"></span><span class="mw-headline" id="Adaptation_to_larger_architectures_(scalability)">Adaptation to larger architectures (scalability)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=13" title="Edit section: Adaptation to larger architectures (scalability)">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In the context of algorithms that run over the very long term (servers, cloud...), the computer architecture evolves over time. However, it is preferable not to have to design a new algorithm each time.  
</p><p>An extremely important parameter of a load balancing algorithm is therefore its ability to adapt to a scalable hardware architecture. This is called the <a href="/wiki/Scalability" title="Scalability">scalability</a> of the algorithm. An algorithm is called scalable for an input parameter when its performance remains relatively independent of the size of that parameter. 
</p><p>When the algorithm is capable of adapting to a varying number of computing units, but the number of computing units must be fixed before execution, it is called moldable. If, on the other hand, the algorithm is capable of dealing with a fluctuating amount of processors during its execution, the algorithm is said to be malleable. Most load balancing algorithms are at least moldable <sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup>.
</p>
<h3><span class="mw-headline" id="Fault_tolerance">Fault tolerance</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=14" title="Edit section: Fault tolerance">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Especially in large-scale <a href="/wiki/Computing_cluster" class="mw-redirect" title="Computing cluster">computing clusters</a>, it is not tolerable to execute a parallel algorithm which cannot withstand failure of one single component. Therefore, <a href="/wiki/Fault_tolerant" class="mw-redirect" title="Fault tolerant">fault tolerant</a> algorithms are being developed which can detect outages of processors and recover the computation.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Approaches">Approaches</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=15" title="Edit section: Approaches">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Static_distribution_with_full_knowledge_of_the_tasks:_prefix_sum">Static distribution with full knowledge of the tasks: <a href="/wiki/Prefix_sum" title="Prefix sum">prefix sum</a></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=16" title="Edit section: Static distribution with full knowledge of the tasks: prefix sum">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>If the tasks are independent of each other, and if their respective execution time and the tasks can be subdivided, there is a simple and optimal algorithm. 
</p><p>By dividing the tasks in such a way as to give the same amount of computation to each processor, all that remains to be done is to group the results together. Using a <a href="/wiki/Prefix_sum" title="Prefix sum">prefix sum</a> algorithm, this division can be calculated in <a href="/wiki/Logarithmic_time" class="mw-redirect" title="Logarithmic time">logarithmic time</a> with respect to the number of processors. 
</p><p><br />
</p>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Load_Balancing_divisible_tasks.png" class="image"><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Load_Balancing_divisible_tasks.png/220px-Load_Balancing_divisible_tasks.png" decoding="async" width="220" height="92" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/0/04/Load_Balancing_divisible_tasks.png/330px-Load_Balancing_divisible_tasks.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/04/Load_Balancing_divisible_tasks.png/440px-Load_Balancing_divisible_tasks.png 2x" data-file-width="1171" data-file-height="492" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Load_Balancing_divisible_tasks.png" class="internal" title="Enlarge"></a></div>Load balancing algorithm depending on divisibility of tasks</div></div></div>
<p>If, however, the tasks cannot be subdivided (i.e. they are atomic), although optimizing task assignment is a difficult problem, it is still possible to approximate a relatively fair distribution of tasks, provided that the size of each of them is much smaller than the total amount of computation performed by each of the nodes.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup> 
</p><p>Most of the time, the execution time of a task is unknown and only rough approximation are available. This algorithm, although particularly efficient, is not viable for these scenarios.  
</p>
<h3><span class="mw-headline" id="Static_load_distribution_without_prior_knowledge">Static load distribution without prior knowledge</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=17" title="Edit section: Static load distribution without prior knowledge">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Even if the execution time is not known in advance at all, static load distribution is always possible. 
</p>
<h4><span class="mw-headline" id="Round-Robin"><a href="/wiki/Round-robin_scheduling" title="Round-robin scheduling"> Round-Robin</a></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=18" title="Edit section: Round-Robin">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In this simple algorithm, the first request is sent to the first server, then the next to the second, and so on down to the last. Then it is started again, assigning the next request to the first server, and so on. 
</p><p>This algorithm can be weighted such that the most powerful units receive the largest number of requests and receive them first. 
</p>
<h4><span class="mw-headline" id="Randomized_static">Randomized static</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=19" title="Edit section: Randomized static">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Randomized static load balancing is simply a matter of randomly assigning tasks to the different servers. This method works quite well. If, on the other hand, the number of tasks is known in advance, it is even more efficient to calculate a random permutation in advance. This avoids communication costs for each assignment. There is no longer a need for a distribution master because everyone knows what task is assigned to him. Even if the number of tasks is unknown, it is still possible to avoid communication with a pseudo-random assignment generation known to all processors. 
</p><p>The performance of this strategy (measured in total execution time for a given fixed set of tasks) decreases with the maximum size of the tasks. 
</p>
<h4><span class="mw-headline" id="Others">Others</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=20" title="Edit section: Others">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Of course, there are other methods of assignment as well: 
</p>
<ul><li>Less work: Assign more tasks to the servers by performing less (the method can also be weighted).</li>
<li>Hash: allocates queries according to a <a href="/wiki/Hash_table" title="Hash table">hash table</a>.</li>
<li>Power of Two Choices: pick two servers at random and choose the better of the two options.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup><sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup></li></ul>
<h3><span class="mw-headline" id="Master-Worker_Scheme">Master-Worker Scheme</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=21" title="Edit section: Master-Worker Scheme">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/Master/slave_(technology)" title="Master/slave (technology)">Master-Worker</a> schemes are among the simplest dynamic load balancing algorithms. A master distributes the workload to all workers (also sometimes referred to as "slaves"). Initially, all workers are idle and report this to the master. The master answers worker requests and distributes the tasks to them. When he has no more tasks to give, he informs the workers so that they stop asking for tasks. 
</p><p>The advantage of this system is that it distributes the burden very fairly. In fact, if one does not take into account the time needed for the assignment, the execution time would be comparable to the prefix sum seen above. 
</p><p>The problem of this algorithm is that it has difficulty to adapt to a large number of processors because of the high amount of necessary communications. This lack of <a href="/wiki/Scalability" title="Scalability">scalability</a> makes it quickly inoperable in very large servers or very large parallel computers. The master acts as a <a href="/wiki/Bottleneck_(software)" title="Bottleneck (software)">bottleneck</a>.
</p>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Master-Worker_and_bottleneck.png" class="image"><img alt="" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Master-Worker_and_bottleneck.png/220px-Master-Worker_and_bottleneck.png" decoding="async" width="220" height="92" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Master-Worker_and_bottleneck.png/330px-Master-Worker_and_bottleneck.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Master-Worker_and_bottleneck.png/440px-Master-Worker_and_bottleneck.png 2x" data-file-width="1065" data-file-height="445" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Master-Worker_and_bottleneck.png" class="internal" title="Enlarge"></a></div>Master-Worker and bottleneck</div></div></div> 
<p>However, the quality of the algorithm can be greatly improved by replacing the master by a task list which can be used by different processors. Although this algorithm is a little more difficult to implement, it promises much better scalability, although still insufficient for very large computing centers. 
</p>
<h3><span id="Non-hierarchical_architecture.2C_without_knowledge_of_the_system:_work_stealing"></span><span class="mw-headline" id="Non-hierarchical_architecture,_without_knowledge_of_the_system:_work_stealing">Non-hierarchical architecture, without knowledge of the system: <a href="/wiki/Work_stealing" title="Work stealing">work stealing</a></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=22" title="Edit section: Non-hierarchical architecture, without knowledge of the system: work stealing">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Another technique to overcome scalability problems when the time needed for task completion is unknown is <a href="/wiki/Work_stealing" title="Work stealing">work stealing</a>.
</p><p>The approach consists of assigning to each processor a certain number of tasks in a random or predefined manner, then allowing inactive processors to "steal" work from active or overloaded processors. Several implementations of this concept exist, defined by a task division model and by the rules determining the exchange between processors. While this technique can be particularly effective, it is difficult to implement because it is necessary to ensure that communication does not become the primary occupation of the processors instead of solving the problem. 
</p><p>In the case of atomic tasks, two main strategies can be distinguished, those where the processors with low load offer their computing capacity to those with the highest load, and those where the most loaded units wish to lighten the workload assigned to them. It has been shown<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup> that when the network is heavily loaded, it is more efficient for the least loaded units to offer their availability and when the network is lightly loaded, it is the overloaded processors that require support from the most inactive ones. This rule of thumb limits the number of exchanged messages. 
</p><p>In the case where one starts from a single large task that cannot be divided beyond an atomic level, there is a very efficient algorithm "Tree-Shaped computation"<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup>, where the parent task is distributed in a work tree.  
</p>
<h4><span class="mw-headline" id="Principle">Principle</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=23" title="Edit section: Principle">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Initially, many processors have an empty task, except one that works sequentially on it. Idle processors issue requests randomly to other processors (not necessarily active). If the latter is able to subdivide the task it is working on, it does so by sending part of its work to the node making the request. Otherwise, it returns an empty task. This induces a tree structure. It is then necessary to send a termination signal to the parent processor when the subtask is completed, so that it in turn sends the message to its parent until it reaches the root of the tree. When the first processor, i.e. the root, has finished, a global termination message can be broadcast. At the end, it is necessary to assemble the results by going back up the tree.
</p>
<h4><span class="mw-headline" id="Efficiency">Efficiency</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=24" title="Edit section: Efficiency">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The efficiency of such an algorithm is close to the prefix sum when the job cutting and communication time is not too high compared to the work to be done. To avoid too high communication costs, it is possible to imagine a list of jobs on shared memory. Therefore, a request is simply reading from a certain position on this shared memory at the request of the master processor. 
</p>
<h2><span class="mw-headline" id="Application">Application</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=25" title="Edit section: Application">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In addition to efficient problem solving through parallel computations, load balancing algorithms are widely used in HTTP request management where a site with a large audience must be able to handle requests per second. 
</p>
<h3><span class="mw-headline" id="Internet-based_services">Internet-based services</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=26" title="Edit section: Internet-based services">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<table class="box-Multiple_issues plainlinks metadata ambox ambox-content ambox-multiple_issues compact-ambox" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><img alt="" src="https://upload.wikimedia.org/wikipedia/en/thumb/b/b4/Ambox_important.svg/40px-Ambox_important.svg.png" decoding="async" width="40" height="40" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/b/b4/Ambox_important.svg/40px-Ambox_important.svg.pngx" data-file-width="40" data-file-height="40" /></div></td><td class="mbox-text"><div class="mbox-text-span"><div class="mw-collapsible" style="width:95%; margin: 0.2em 0;"><b>This section has multiple issues.</b> Please help <b><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Load_balancing_(computing)&amp;action=edit">improve it</a></b> or discuss these issues on the <b><a href="/wiki/Talk:Load_balancing_(computing)" title="Talk:Load balancing (computing)">talk page</a></b>. <small><i>(<a href="/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">Learn how and when to remove these template messages</a>)</i></small>
<div class="mw-collapsible-content" style="margin-top: 0.3em;">
      <table class="box-Cleanup plainlinks metadata ambox ambox-style ambox-Cleanup" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png" decoding="async" width="40" height="40" srcset="//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/60px-Edit-clear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/80px-Edit-clear.svg.png 2x" data-file-width="48" data-file-height="48" /></div></td><td class="mbox-text"><div class="mbox-text-span">This section may <b>require <a href="/wiki/Wikipedia:Cleanup" title="Wikipedia:Cleanup">cleanup</a></b> to meet Wikipedia's <a href="/wiki/Wikipedia:Manual_of_Style" title="Wikipedia:Manual of Style">quality standards</a>.<span class="hide-when-compact"> No <a href="/wiki/Template:Cleanup/doc" title="Template:Cleanup/doc">cleanup reason</a> has been specified. Please help <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Load_balancing_(computing)&amp;action=edit">improve this section</a> if you can.</span>  <small class="date-container"><i>(<span class="date">December 2010</span>)</i></small><small class="hide-when-compact"><i> (<a href="/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>
<table class="box-More_citations_needed plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><a href="/wiki/File:Question_book-new.svg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" decoding="async" width="50" height="39" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x" data-file-width="512" data-file-height="399" /></a></div></td><td class="mbox-text"><div class="mbox-text-span">This article's section <b>needs additional citations for <a href="/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability">verification</a></b>.<span class="hide-when-compact"> Please help <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Load_balancing_(computing)&amp;action=edit">improve this article</a> by <a href="/wiki/Help:Referencing_for_beginners" title="Help:Referencing for beginners">adding citations to reliable sources</a>. Unsourced material may be challenged and removed.<br /><small><span class="plainlinks"><i>Find sources:</i>&#160;<a rel="nofollow" class="external text" href="//www.google.com/search?as_eq=wikipedia&amp;q=%22Load+balancing%22+computing">"Load balancing"&#160;computing</a>&#160;–&#160;<a rel="nofollow" class="external text" href="//www.google.com/search?tbm=nws&amp;q=%22Load+balancing%22+computing+-wikipedia">news</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="//www.google.com/search?&amp;q=%22Load+balancing%22+computing+site:news.google.com/newspapers&amp;source=newspapers">newspapers</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="//www.google.com/search?tbs=bks:1&amp;q=%22Load+balancing%22+computing+-wikipedia">books</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="//scholar.google.com/scholar?q=%22Load+balancing%22+computing">scholar</a>&#160;<b>·</b> <a rel="nofollow" class="external text" href="https://www.jstor.org/action/doBasicSearch?Query=%22Load+balancing%22+computing&amp;acc=on&amp;wc=on">JSTOR</a></span></small></span>  <small class="date-container"><i>(<span class="date">December 2010</span>)</i></small><small class="hide-when-compact"><i> (<a href="/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>
    </div>
</div><small class="hide-when-compact"><i> (<a href="/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>
<p>One of the most commonly used applications of load balancing is to provide a single Internet service from multiple <a href="/wiki/Server_(computing)" title="Server (computing)">servers</a>, sometimes known as a <a href="/wiki/Server_farm" title="Server farm">server farm</a>. Commonly load-balanced systems include popular <a href="/wiki/Web_site" class="mw-redirect" title="Web site">web sites</a>, large <a href="/wiki/Internet_Relay_Chat" title="Internet Relay Chat">Internet Relay Chat</a> networks, high-bandwidth <a href="/wiki/File_Transfer_Protocol" title="File Transfer Protocol">File Transfer Protocol</a> sites, <a href="/wiki/Network_News_Transfer_Protocol" title="Network News Transfer Protocol">Network News Transfer Protocol</a> (NNTP) servers, <a href="/wiki/Domain_Name_System" title="Domain Name System">Domain Name System</a> (DNS) servers, and databases.
</p>
<h4><span class="mw-headline" id="Round-robin_DNS">Round-robin DNS</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=27" title="Edit section: Round-robin DNS">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Round-robin_DNS" title="Round-robin DNS">Round-robin DNS</a></div>
<p>An alternate method of load balancing, which does not require a dedicated software or hardware node, is called <i><a href="/wiki/Round-robin_DNS" title="Round-robin DNS">round-robin DNS</a></i>.
In this technique, multiple <a href="/wiki/IP_address" title="IP address">IP addresses</a> are associated with a single <a href="/wiki/Domain_name" title="Domain name">domain name</a>; clients are given IP in a round-robin fashion. IP is assigned to clients with a short expiration so the client is more likely to use a different IP the next time they access the Internet service being requested.
</p>
<h4><span class="mw-headline" id="DNS_delegation">DNS delegation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=28" title="Edit section: DNS delegation">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Another more effective technique for load-balancing using DNS is to delegate <style data-mw-deduplicate="TemplateStyles:r886049734">.mw-parser-output .monospaced{font-family:monospace,monospace}</style><span class="monospaced">www.example.org</span> as a sub-domain whose zone is served by each of the same servers that are serving the web site. This technique works particularly well where individual servers are spread geographically on the Internet. For example:
</p>
<pre>one.example.org A 192.0.2.1
two.example.org A 203.0.113.2
www.example.org NS one.example.org
www.example.org NS two.example.org
</pre>
<p>However, the zone file for <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886049734"/><span class="monospaced">www.example.org</span> on each server is different such that each server resolves its own IP Address as the A-record.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup> On server <i>one</i> the zone file for <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886049734"/><span class="monospaced">www.example.org</span> reports:
</p>
<pre>@ in a 192.0.2.1
</pre>
<p>On server <i>two</i> the same zone file contains:
</p>
<pre>@ in a 203.0.113.2
</pre>
<p>This way, when a server is down, its DNS will not respond and the web service does not receive any traffic. If the line to one server is congested, the unreliability of DNS ensures less HTTP traffic reaches that server. Furthermore, the quickest DNS response to the resolver is nearly always the one from the network's closest server, ensuring geo-sensitive load-balancing<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (November 2014)">citation needed</span></a></i>&#93;</sup>. A short <a href="/wiki/Time_to_live" title="Time to live">TTL</a> on the A-record helps to ensure traffic is quickly diverted when a server goes down. Consideration must be given the possibility that this technique may cause individual clients to switch between individual servers in mid-session.
</p>
<h4><span class="mw-headline" id="Client-side_random_load_balancing">Client-side random load balancing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=29" title="Edit section: Client-side random load balancing">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Another approach to load balancing is to deliver a list of server IPs to the client, and then to have client randomly select the IP from the list on each connection.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup><sup id="cite_ref-ithare_13-0" class="reference"><a href="#cite_note-ithare-13">&#91;13&#93;</a></sup> This essentially relies on all clients generating similar loads, and the <a href="/wiki/Law_of_Large_Numbers" class="mw-redirect" title="Law of Large Numbers">Law of Large Numbers</a><sup id="cite_ref-ithare_13-1" class="reference"><a href="#cite_note-ithare-13">&#91;13&#93;</a></sup> to achieve a reasonably flat load distribution across servers. It has been claimed that client-side random load balancing tends to provide better load distribution than round-robin DNS; this has been attributed to caching issues with round-robin DNS, that in case of large DNS caching servers, tend to skew the distribution for round-robin DNS, while client-side random selection remains unaffected regardless of DNS caching.<sup id="cite_ref-ithare_13-2" class="reference"><a href="#cite_note-ithare-13">&#91;13&#93;</a></sup>
</p><p>With this approach, the method of delivery of list of IPs to the client can vary, and may be implemented as a DNS list (delivered to all the clients without any round-robin), or via hardcoding it to the list. If a "smart client" is used, detecting that randomly selected server is down and connecting randomly again, it also provides fault tolerance.
</p>
<h4><span class="mw-headline" id="Server-side_load_balancers">Server-side load balancers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=30" title="Edit section: Server-side load balancers">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>For Internet services, a server-side load balancer is usually a software program that is listening on the <a href="/wiki/TCP_and_UDP_port" class="mw-redirect" title="TCP and UDP port">port</a> where external clients connect to access services.  The load balancer forwards requests to one of the "backend" servers, which usually replies to the load balancer. This allows the load balancer to reply to the client without the client ever knowing about the internal separation of functions. It also prevents clients from contacting back-end servers directly, which may have security benefits by hiding the structure of the internal network and preventing attacks on the kernel's network stack or unrelated services running on other ports.
</p><p>Some load balancers provide a mechanism for doing something special in the event that all backend servers are unavailable.
This might include forwarding to a backup load balancer or displaying a message regarding the outage.
</p><p>It is also important that the load balancer itself does not become a <a href="/wiki/Single_point_of_failure" title="Single point of failure">single point of failure</a>. Usually, load balancers are implemented in <a href="/wiki/High_availability" title="High availability">high-availability</a> pairs which may also replicate session persistence data if required by the specific application.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup> Certain applications are programmed with immunity to this problem, by offsetting the load balancing point over differential sharing platforms beyond the defined network. The sequential algorithms paired to these functions are defined by flexible parameters unique to the specific database.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup>
</p>
<h5><span class="mw-headline" id="Scheduling_algorithms">Scheduling algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=31" title="Edit section: Scheduling algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>Numerous <a href="/wiki/Scheduling_algorithm" class="mw-redirect" title="Scheduling algorithm">scheduling algorithms</a>, also called load-balancing methods, are used by load balancers to determine which back-end server to send a request to.
Simple algorithms include random choice, <a href="/wiki/Round-robin_scheduling" title="Round-robin scheduling">round robin</a>, or least connections.<sup id="cite_ref-:0_16-0" class="reference"><a href="#cite_note-:0-16">&#91;16&#93;</a></sup> More sophisticated load balancers may take additional factors into account, such as a server's reported load, least response times, up/down status (determined by a monitoring poll of some kind), number of active connections, geographic location, capabilities, or how much traffic it has recently been assigned.
</p>
<h5><span class="mw-headline" id="Persistence">Persistence</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=32" title="Edit section: Persistence">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>An important issue when operating a load-balanced service is how to handle information that must be kept across the multiple requests in a user's session. If this information is stored locally on one backend server, then subsequent requests going to different backend servers would not be able to find it. This might be cached information that can be recomputed, in which case load-balancing a request to a different backend server just introduces a performance issue.<sup id="cite_ref-:0_16-1" class="reference"><a href="#cite_note-:0-16">&#91;16&#93;</a></sup>
</p><p>Ideally, the cluster of servers behind the load balancer should not be session-aware, so that if a client connects to any backend server at any time the user experience is unaffected.  This is usually achieved with a shared database or an in-memory session database, for example <a href="/wiki/Memcached" title="Memcached">Memcached</a>.
</p><p>One basic solution to the session data issue is to send all requests in a user session consistently to the same backend server. This is known as "persistence" or "stickiness". A significant downside to this technique is its lack of automatic <a href="/wiki/Failover" title="Failover">failover</a>: if a backend server goes down, its per-session information becomes inaccessible, and any sessions depending on it are lost. The same problem is usually relevant to central database servers; even if web servers are "stateless" and not "sticky", the central database is (see below).
</p><p>Assignment to a particular server might be based on a username, client IP address, or be random. Because of changes of the client's perceived address resulting from <a href="/wiki/DHCP" class="mw-redirect" title="DHCP">DHCP</a>, <a href="/wiki/Network_address_translation" title="Network address translation">network address translation</a>, and <a href="/wiki/Web_proxy" class="mw-redirect" title="Web proxy">web proxies</a> this method may be unreliable. Random assignments must be remembered by the load balancer, which creates a burden on storage. If the load balancer is replaced or fails, this information may be lost, and assignments may need to be deleted after a timeout period or during periods of high load to avoid exceeding the space available for the assignment table. The random assignment method also requires that clients maintain some state, which can be a problem, for example when a web browser has disabled storage of cookies. Sophisticated load balancers use multiple persistence techniques to avoid some of the shortcomings of any one method.
</p><p>Another solution is to keep the per-session data in a <a href="/wiki/Database" title="Database">database</a>. Generally, this is bad for performance because it increases the load on the database: the database is best used to store information less transient than per-session data. To prevent a database from becoming a <a href="/wiki/Single_point_of_failure" title="Single point of failure">single point of failure</a>, and to improve <a href="/wiki/Scalability" title="Scalability">scalability</a>, the database is often replicated across multiple machines, and load balancing is used to spread the query load across those replicas.  <a href="/wiki/Microsoft" title="Microsoft">Microsoft</a>'s <a href="/wiki/ASP.net" class="mw-redirect" title="ASP.net">ASP.net</a> State Server technology is an example of a session database. All servers in a web farm store their session data on State Server and any server in the farm can retrieve the data.
</p><p>In the very common case where the client is a web browser, a simple but efficient approach is to store the per-session data in the browser itself. One way to achieve this is to use a <a href="/wiki/HTTP_cookie" title="HTTP cookie">browser cookie</a>, suitably time-stamped and encrypted. Another is <a href="/wiki/URL_rewriting" class="mw-redirect" title="URL rewriting">URL rewriting</a>. Storing session data on the client is generally the preferred solution: then the load balancer is free to pick any backend server to handle a request. However, this method of state-data handling is poorly suited to some complex business logic scenarios, where session state payload is big and recomputing it with every request on a server is not feasible. URL rewriting has major security issues, because the end-user can easily alter the submitted URL and thus change session streams.
</p><p>Yet another solution to storing persistent data is to associate a name with each block of data, and use a <a href="/wiki/Distributed_hash_table" title="Distributed hash table">distributed hash table</a> to pseudo-randomly assign that name to one of the available servers, and then store that block of data in the assigned server.
</p>
<h5><span class="mw-headline" id="Load_balancer_features">Load balancer features</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=33" title="Edit section: Load balancer features">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>Hardware and software load balancers may have a variety of special features. The fundamental feature of a load balancer is to be able to distribute incoming requests over a number of backend servers in the cluster according to a scheduling algorithm. Most of the following features are vendor specific:
</p>
<dl><dt>Asymmetric load</dt>
<dd>A ratio can be manually assigned to cause some backend servers to get a greater share of the workload than others. This is sometimes used as a crude way to account for some servers having more capacity than others and may not always work as desired.</dd>
<dt>Priority activation</dt>
<dd>When the number of available servers drops below a certain number, or load gets too high, standby servers can be brought online.</dd>
<dt><a href="/wiki/TLS_acceleration" title="TLS acceleration">TLS Offload and Acceleration</a></dt>
<dd>TLS (or its predecessor SSL) acceleration is a technique of offloading cryptographic protocol calculations onto a specialized hardware. Depending on the workload, processing the encryption and authentication requirements of an <a href="/wiki/Transport_Layer_Security" title="Transport Layer Security">TLS</a> request can become a major part of the demand on the Web Server's CPU; as the demand increases, users will see slower response times, as the TLS overhead is distributed among Web servers. To remove this demand on Web servers, a balancer can terminate TLS connections, passing HTTPS requests as HTTP requests to the Web servers. If the balancer itself is not overloaded, this does not noticeably degrade the performance perceived by end users. The downside of this approach is that all of the TLS processing is concentrated on a single device (the balancer) which can become a new bottleneck. Some load balancer appliances include specialized hardware to process TLS. Instead of upgrading the load balancer, which is quite expensive dedicated hardware, it may be cheaper to forgo TLS offload and add a few Web servers. Also, some server vendors such as Oracle/Sun now incorporate cryptographic acceleration hardware into their CPUs such as the T2000. F5 Networks incorporates a dedicated TLS acceleration hardware card in their local traffic manager (LTM) which is used for encrypting and decrypting TLS traffic. One clear benefit to TLS offloading in the balancer is that it enables it to do balancing or content switching based on data in the HTTPS request.</dd>
<dt><a href="/wiki/Distributed_denial_of_service" class="mw-redirect" title="Distributed denial of service">Distributed Denial of Service</a> (DDoS) attack protection</dt>
<dd>Load balancers can provide features such as <a href="/wiki/SYN_cookies" title="SYN cookies">SYN cookies</a> and delayed-binding (the back-end servers don't see the client until it finishes its TCP handshake) to mitigate <a href="/wiki/SYN_flood" title="SYN flood">SYN flood</a> attacks and generally offload work from the servers to a more efficient platform.</dd>
<dt><a href="/wiki/HTTP_compression" title="HTTP compression">HTTP compression</a></dt>
<dd>HTTP compression reduces the amount of data to be transferred for HTTP objects by utilising gzip compression available in all modern web browsers.  The larger the response and the further away the client is, the more this feature can improve response times.  The trade-off is that this feature puts additional CPU demand on the load balancer and could be done by web servers instead.</dd>
<dt>TCP offload</dt>
<dd>Different vendors use different terms for this, but the idea is that normally each HTTP request from each client is a different TCP connection.  This feature utilises HTTP/1.1 to consolidate multiple HTTP requests from multiple clients into a single TCP socket to the back-end servers.</dd>
<dt>TCP buffering</dt>
<dd>The load balancer can buffer responses from the server and spoon-feed the data out to slow clients, allowing the web server to free a thread for other tasks faster than it would if it had to send the entire request to the client directly.</dd>
<dt>Direct Server Return</dt>
<dd>An option for asymmetrical load distribution, where request and reply have different network paths.</dd>
<dt>Health checking</dt>
<dd>The balancer polls servers for application layer health and removes failed servers from the pool.</dd>
<dt><a href="/wiki/HTTP_caching" class="mw-redirect" title="HTTP caching">HTTP caching</a></dt>
<dd>The balancer stores static content so that some requests can be handled without contacting the servers.</dd>
<dt>Content filtering</dt>
<dd>Some balancers can arbitrarily modify traffic on the way through.</dd>
<dt>HTTP security</dt>
<dd>Some balancers can hide HTTP error pages, remove server identification headers from HTTP responses, and encrypt cookies so that end users cannot manipulate them.</dd>
<dt><a href="/wiki/Priority_queuing" class="mw-redirect" title="Priority queuing">Priority queuing</a></dt>
<dd>Also known as <a href="/wiki/Rate_shaping" class="mw-redirect" title="Rate shaping">rate shaping</a>, the ability to give different priority to different traffic.</dd>
<dt>Content-aware switching</dt>
<dd>Most load balancers can send requests to different servers based on the URL being requested, assuming the request is not encrypted (HTTP) or if it is encrypted (via HTTPS) that the HTTPS request is terminated (decrypted) at the load balancer.</dd>
<dt>Client authentication</dt>
<dd>Authenticate users against a variety of authentication sources before allowing them access to a website.</dd>
<dt>Programmatic traffic manipulation</dt>
<dd>At least one balancer allows the use of a scripting language to allow custom balancing methods, arbitrary traffic manipulations, and more.</dd>
<dt><a href="/wiki/Firewall_(networking)" class="mw-redirect" title="Firewall (networking)">Firewall</a></dt>
<dd>Firewalls can prevent direct connections to backend servers, for network security reasons.</dd>
<dt><a href="/wiki/Intrusion_prevention_system" class="mw-redirect" title="Intrusion prevention system">Intrusion prevention system</a></dt>
<dd>Intrusion prevention systems offer application layer security in addition to network/transport layer offered by firewall security.</dd></dl>
<h3><span class="mw-headline" id="Use_in_telecommunications">Use in telecommunications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=34" title="Edit section: Use in telecommunications">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Load balancing can be useful in applications with redundant communications links.  For example, a company may have multiple Internet connections ensuring network access if one of the connections fails. A <a href="/wiki/Failover" title="Failover">failover</a> arrangement would mean that one link is designated for normal use, while the second link is used only if the primary link fails.
</p><p>Using load balancing, both links can be in use all the time.  A device or program monitors the availability of all links and selects the path for sending packets. The use of multiple links simultaneously increases the available bandwidth.
</p>
<h4><span class="mw-headline" id="Shortest_Path_Bridging">Shortest Path Bridging</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=35" title="Edit section: Shortest Path Bridging">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Shortest_Path_Bridging" class="mw-redirect" title="Shortest Path Bridging">Shortest Path Bridging</a></div>
<p>The IEEE approved the <a href="/wiki/IEEE_802.1aq" title="IEEE 802.1aq">IEEE 802.1aq</a> standard May 2012,<sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup> also known and documented in most books as <a href="/wiki/Shortest_Path_Bridging" class="mw-redirect" title="Shortest Path Bridging">Shortest Path Bridging (SPB)</a>.  SPB allows all links to be active through multiple equal cost paths, provides faster convergence times to reduce down time, and simplifies the use of load balancing in <a href="/wiki/Network_topology#Mesh" title="Network topology">mesh network topologies</a> (partially connected and/or fully connected) by allowing traffic to load share across all paths of a network.<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup><sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup> SPB is designed to virtually eliminate human error during configuration and preserves the plug-and-play nature that established Ethernet as the de facto protocol at Layer 2.<sup id="cite_ref-IEEE_20-0" class="reference"><a href="#cite_note-IEEE-20">&#91;20&#93;</a></sup>
</p>
<h4><span class="mw-headline" id="Routing_1">Routing 1</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=36" title="Edit section: Routing 1">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<div role="note" class="hatnote navigation-not-searchable">Further information: <a href="/wiki/Routing" title="Routing">Routing</a></div>
<p>Many telecommunications companies have multiple routes through their networks or to external networks.  They use sophisticated load balancing to shift traffic from one path to another to avoid <a href="/wiki/Network_congestion" title="Network congestion">network congestion</a> on any particular link, and sometimes to minimize the cost of transit across external networks or improve <a href="/wiki/Reliability_(computer_networking)" title="Reliability (computer networking)">network reliability</a>.
</p><p>Another way of using load balancing is in <a href="/wiki/Network_monitoring" title="Network monitoring">network monitoring</a> activities. Load balancers can be used to split huge data flows into several sub-flows and use several network analyzers, each reading a part of the original data. This is very useful for monitoring fast networks like <a href="/wiki/10_Gigabit_Ethernet" title="10 Gigabit Ethernet">10GbE</a> or STM64, where complex processing of the data may not be possible at <a href="/wiki/Wire_speed" title="Wire speed">wire speed</a>.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Use_in_datacenter_networks">Use in datacenter networks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=37" title="Edit section: Use in datacenter networks">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Load balancing is widely used in datacenter networks to distribute traffic across many existing paths between any two servers.<sup id="cite_ref-architecture_22-0" class="reference"><a href="#cite_note-architecture-22">&#91;22&#93;</a></sup> It allows more efficient use of network bandwidth and reduces provisioning costs. In general, load balancing in datacenter networks can be classified as either static or dynamic. Static load balancing distributes traffic by computing a hash of the source and destination addresses and port numbers of traffic flows and using it to determine how flows are assigned to one of the existing paths. Dynamic load balancing assigns traffic flows to paths by monitoring bandwidth utilization of different paths. Dynamic assignment can also be proactive or reactive. In the former case, the assignment is fixed once made, while in the latter the network logic keeps monitoring available paths and shifts flows across them as network utilization changes (with arrival of new flows or completion of existing ones). A comprehensive overview of load balancing in datacenter networks has been made available.<sup id="cite_ref-architecture_22-1" class="reference"><a href="#cite_note-architecture-22">&#91;22&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Relationship_to_failovers">Relationship to failovers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=38" title="Edit section: Relationship to failovers">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Load balancing is often used to implement <a href="/wiki/Failover" title="Failover">failover</a>—the continuation of a service after the failure of one or more of its components.  The components are monitored continually (e.g., web servers may be monitored by fetching known pages), and when one becomes non-responsive, the load balancer is informed and no longer sends traffic to it.  When a component comes back online, the load balancer begins to route traffic to it again.  For this to work, there must be at least one component in excess of the service's capacity (<a href="/wiki/N%2B1_redundancy" title="N+1 redundancy">N+1 redundancy</a>).  This can be much less expensive and more flexible than failover approaches where each single live component is paired with a single backup component that takes over in the event of a failure (<a href="/wiki/Dual_modular_redundancy" title="Dual modular redundancy">dual modular redundancy</a>).  Some types of <a href="/wiki/RAID" title="RAID">RAID</a> systems can also utilize <a href="/wiki/Hot_spare" title="Hot spare">hot spare</a> for a similar effect.<sup id="cite_ref-IBM_23-0" class="reference"><a href="#cite_note-IBM-23">&#91;23&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=39" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="div-col columns column-width" style="-moz-column-width: 25em; -webkit-column-width: 25em; column-width: 25em;">
<ul><li><a href="/wiki/Affinity_mask" title="Affinity mask">Affinity mask</a></li>
<li><a href="/wiki/Application_Delivery_Controller" class="mw-redirect" title="Application Delivery Controller">Application Delivery Controller</a></li>
<li><a href="/wiki/Autoscaling" title="Autoscaling">Autoscaling</a></li>
<li><a href="/wiki/Cloud_computing" title="Cloud computing">Cloud computing</a></li>
<li><a href="/wiki/Common_Address_Redundancy_Protocol" title="Common Address Redundancy Protocol">Common Address Redundancy Protocol</a></li>
<li><a href="/wiki/Edge_computing" title="Edge computing">Edge computing</a></li>
<li><a href="/wiki/Fog_computing" title="Fog computing">Fog computing</a></li>
<li><a href="/wiki/Network_Load_Balancing" title="Network Load Balancing">Network Load Balancing</a></li>
<li><a href="/wiki/Network_Load_Balancing_Services" title="Network Load Balancing Services">Network Load Balancing Services</a></li>
<li><a href="/wiki/Partition_(database)" title="Partition (database)">Partition (database)</a></li>
<li><a href="/wiki/Processor_affinity" title="Processor affinity">Processor affinity</a></li>
<li><a href="/wiki/SRV_record" title="SRV record">SRV record</a></li>
<li><a href="/wiki/Transposition-driven_scheduling" title="Transposition-driven scheduling">Transposition-driven scheduling</a></li></ul>
</div>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=40" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite id="CITEREFSandersMehlhornDietzfelbingerDementiev2019" class="citation book cs1">Sanders, Peter; Mehlhorn, Kurt; Dietzfelbinger, Martin; Dementiev, Roman (11 September 2019). <i>Sequential and parallel algorithms and data structures&#160;: the basic toolbox</i>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-030-25208-3" title="Special:BookSources/978-3-030-25208-3"><bdi>978-3-030-25208-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Sequential+and+parallel+algorithms+and+data+structures+%3A+the+basic+toolbox&amp;rft.date=2019-09-11&amp;rft.isbn=978-3-030-25208-3&amp;rft.aulast=Sanders&amp;rft.aufirst=Peter&amp;rft.au=Mehlhorn%2C+Kurt&amp;rft.au=Dietzfelbinger%2C+Martin&amp;rft.au=Dementiev%2C+Roman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r951705291">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg");background-repeat:no-repeat;background-size:12px;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite id="CITEREFLiuCaiJinShen2016" class="citation journal cs1">Liu, Qi; Cai, Weidong; Jin, Dandan; Shen, Jian; Fu, Zhangjie; Liu, Xiaodong; Linge, Nigel (30 August 2016). "Estimation Accuracy on Execution Time of Run-Time Tasks in a Heterogeneous Distributed Environment". <i>Sensors</i>. <b>16</b> (9): 1386. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.3390%2Fs16091386">10.3390/s16091386</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/27589753">27589753</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:391429">391429</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sensors&amp;rft.atitle=Estimation+Accuracy+on+Execution+Time+of+Run-Time+Tasks+in+a+Heterogeneous+Distributed+Environment&amp;rft.volume=16&amp;rft.issue=9&amp;rft.pages=1386&amp;rft.date=2016-08-30&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A391429&amp;rft_id=info%3Apmid%2F27589753&amp;rft_id=info%3Adoi%2F10.3390%2Fs16091386&amp;rft.aulast=Liu&amp;rft.aufirst=Qi&amp;rft.au=Cai%2C+Weidong&amp;rft.au=Jin%2C+Dandan&amp;rft.au=Shen%2C+Jian&amp;rft.au=Fu%2C+Zhangjie&amp;rft.au=Liu%2C+Xiaodong&amp;rft.au=Linge%2C+Nigel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite id="CITEREFAlakeel2009" class="citation journal cs1">Alakeel, Ali (November 2009). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/268200851">"A Guide to Dynamic Load Balancing in Distributed Computer Systems"</a>. <i>International Journal of Computer Science and Network Security (IJCSNS)</i>. <b>10</b>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Computer+Science+and+Network+Security+%28IJCSNS%29&amp;rft.atitle=A+Guide+to+Dynamic+Load+Balancing+in+Distributed+Computer+Systems&amp;rft.volume=10&amp;rft.date=2009-11&amp;rft.aulast=Alakeel&amp;rft.aufirst=Ali&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F268200851&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite id="CITEREFAsgharAubanelBremner2013" class="citation journal cs1">Asghar, Sajjad; Aubanel, Eric; Bremner, David (October 2013). "A Dynamic Moldable Job Scheduling Based Parallel SAT Solver". <i>2013 42nd International Conference on Parallel Processing</i>: 110–119. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICPP.2013.20">10.1109/ICPP.2013.20</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7695-5117-3" title="Special:BookSources/978-0-7695-5117-3"><bdi>978-0-7695-5117-3</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:15124201">15124201</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=2013+42nd+International+Conference+on+Parallel+Processing&amp;rft.atitle=A+Dynamic+Moldable+Job+Scheduling+Based+Parallel+SAT+Solver&amp;rft.pages=110-119&amp;rft.date=2013-10&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A15124201&amp;rft_id=info%3Adoi%2F10.1109%2FICPP.2013.20&amp;rft.isbn=978-0-7695-5117-3&amp;rft.aulast=Asghar&amp;rft.aufirst=Sajjad&amp;rft.au=Aubanel%2C+Eric&amp;rft.au=Bremner%2C+David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite id="CITEREFPunetha_SarmilaGnanambigaiDinadayalan2015" class="citation journal cs1">Punetha Sarmila, G.; Gnanambigai, N.; Dinadayalan, P. (2015). "Survey on fault tolerant — Load balancing algorithmsin cloud computing". <i>2nd International Conference on Electronics and Communication Systems (ICECS)</i>: 1715–1720. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FECS.2015.7124879">10.1109/ECS.2015.7124879</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4799-7225-8" title="Special:BookSources/978-1-4799-7225-8"><bdi>978-1-4799-7225-8</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:30175022">30175022</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=2nd+International+Conference+on+Electronics+and+Communication+Systems+%28ICECS%29&amp;rft.atitle=Survey+on+fault+tolerant+%E2%80%94+Load+balancing+algorithmsin+cloud+computing&amp;rft.pages=1715-1720&amp;rft.date=2015&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A30175022&amp;rft_id=info%3Adoi%2F10.1109%2FECS.2015.7124879&amp;rft.isbn=978-1-4799-7225-8&amp;rft.aulast=Punetha+Sarmila&amp;rft.aufirst=G.&amp;rft.au=Gnanambigai%2C+N.&amp;rft.au=Dinadayalan%2C+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite id="CITEREFSandersMehlhornDietzfelbingerDementiev2019" class="citation book cs1">Sanders, Peter; Mehlhorn, Kurt; Dietzfelbinger, Martin; Dementiev, Roman (11 September 2019). <i>Sequential and parallel algorithms and data structures&#160;: the basic toolbox</i>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-030-25208-3" title="Special:BookSources/978-3-030-25208-3"><bdi>978-3-030-25208-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Sequential+and+parallel+algorithms+and+data+structures+%3A+the+basic+toolbox&amp;rft.date=2019-09-11&amp;rft.isbn=978-3-030-25208-3&amp;rft.aulast=Sanders&amp;rft.aufirst=Peter&amp;rft.au=Mehlhorn%2C+Kurt&amp;rft.au=Dietzfelbinger%2C+Martin&amp;rft.au=Dementiev%2C+Roman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20191212194243/https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/">"NGINX and the "Power of Two Choices" Load-Balancing Algorithm"</a>. <i>nginx.com</i>. 2018-11-12. Archived from <a rel="nofollow" class="external text" href="https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/">the original</a> on 2019-12-12.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=nginx.com&amp;rft.atitle=NGINX+and+the+%22Power+of+Two+Choices%22+Load-Balancing+Algorithm&amp;rft.date=2018-11-12&amp;rft_id=https%3A%2F%2Fwww.nginx.com%2Fblog%2Fnginx-power-of-two-choices-load-balancing-algorithm%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20190215173140/https://www.haproxy.com/blog/power-of-two-load-balancing/">"Test Driving "Power of Two Random Choices" Load Balancing"</a>. <i>haproxy.com</i>. 2019-02-15. Archived from <a rel="nofollow" class="external text" href="https://www.haproxy.com/blog/power-of-two-load-balancing/">the original</a> on 2019-02-15.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=haproxy.com&amp;rft.atitle=Test+Driving+%22Power+of+Two+Random+Choices%22+Load+Balancing&amp;rft.date=2019-02-15&amp;rft_id=https%3A%2F%2Fwww.haproxy.com%2Fblog%2Fpower-of-two-load-balancing%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite id="CITEREFEagerLazowskaZahorjan1986" class="citation journal cs1">Eager, Derek L; Lazowska, Edward D; Zahorjan, John (1 March 1986). "A comparison of receiver-initiated and sender-initiated adaptive load sharing". <i>Performance Evaluation</i>. <b>6</b> (1): 53–68. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2F0166-5316%2886%2990008-8">10.1016/0166-5316(86)90008-8</a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0166-5316">0166-5316</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Performance+Evaluation&amp;rft.atitle=A+comparison+of+receiver-initiated+and+sender-initiated+adaptive+load+sharing&amp;rft.volume=6&amp;rft.issue=1&amp;rft.pages=53-68&amp;rft.date=1986-03-01&amp;rft_id=info%3Adoi%2F10.1016%2F0166-5316%2886%2990008-8&amp;rft.issn=0166-5316&amp;rft.aulast=Eager&amp;rft.aufirst=Derek+L&amp;rft.au=Lazowska%2C+Edward+D&amp;rft.au=Zahorjan%2C+John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite id="CITEREFSanders1998" class="citation journal cs1">Sanders, Peter (1998). "Tree Shaped Computations as a Model for Parallel Applications". <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.5445%2Fir%2F1000074497">10.5445/ir/1000074497</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Tree+Shaped+Computations+as+a+Model+for+Parallel+Applications&amp;rft.date=1998&amp;rft_id=info%3Adoi%2F10.5445%2Fir%2F1000074497&amp;rft.aulast=Sanders&amp;rft.aufirst=Peter&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.zytrax.com/books/dns/ch8/a.html">IPv4 Address Record (A)</a></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://gameserverarchitecture.com/2015/10/pattern-client-side-load-balancing/">Pattern: Client Side Load Balancing</a></span>
</li>
<li id="cite_note-ithare-13"><span class="mw-cite-backlink">^ <a href="#cite_ref-ithare_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ithare_13-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-ithare_13-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://ithare.com/chapter-vib-server-side-architecture-front-end-servers-and-client-side-random-load-balancing/">MMOG Server-Side Architecture. Front-End Servers and Client-Side Random Load Balancing</a></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.linuxvirtualserver.org/HighAvailability.html">"High Availability"</a>. linuxvirtualserver.org<span class="reference-accessdate">. Retrieved <span class="nowrap">2013-11-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=High+Availability&amp;rft.pub=linuxvirtualserver.org&amp;rft_id=http%3A%2F%2Fwww.linuxvirtualserver.org%2FHighAvailability.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><cite id="CITEREFRanjan2010" class="citation journal cs1">Ranjan, R (2010). "Peer-to-peer cloud provisioning: Service discovery and load-balancing". <i>Cloud Computing</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cloud+Computing&amp;rft.atitle=Peer-to-peer+cloud+provisioning%3A+Service+discovery+and+load-balancing&amp;rft.date=2010&amp;rft.aulast=Ranjan&amp;rft.aufirst=R&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-:0-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-:0_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_16-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20171205223948/https://f5.com/resources/white-papers/load-balancing-101-nuts-and-bolts">"Load Balancing 101: Nuts and Bolts"</a>. <a href="/wiki/F5_Networks" title="F5 Networks">F5 Networks</a>. 2017-12-05. Archived from <a rel="nofollow" class="external text" href="https://f5.com/resources/white-papers/load-balancing-101-nuts-and-bolts">the original</a> on 2017-12-05<span class="reference-accessdate">. Retrieved <span class="nowrap">2018-03-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Load+Balancing+101%3A+Nuts+and+Bolts&amp;rft.pub=F5+Networks&amp;rft.date=2017-12-05&amp;rft_id=https%3A%2F%2Ff5.com%2Fresources%2Fwhite-papers%2Fload-balancing-101-nuts-and-bolts&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text">
<cite id="CITEREFShuang_Yu2012" class="citation web cs1">Shuang Yu (8 May 2012). <a rel="nofollow" class="external text" href="http://standards.ieee.org/news/2012/802.1aq.html">"IEEE APPROVES NEW IEEE 802.1aq™ SHORTEST PATH BRIDGING STANDARD"</a>. IEEE<span class="reference-accessdate">. Retrieved <span class="nowrap">2 June</span> 2012</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+APPROVES+NEW+IEEE+802.1aq%E2%84%A2+SHORTEST+PATH+BRIDGING+STANDARD&amp;rft.pub=IEEE&amp;rft.date=2012-05-08&amp;rft.au=Shuang+Yu&amp;rft_id=http%3A%2F%2Fstandards.ieee.org%2Fnews%2F2012%2F802.1aq.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite id="CITEREFPeter_Ashwood-Smith2011" class="citation web cs1">Peter Ashwood-Smith (24 Feb 2011). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130515115628/http://meetings.apnic.net/__data/assets/pdf_file/0012/32007/APRICOT_SPB_Overview.pdf">"Shortest Path Bridging IEEE 802.1aq Overview"</a> <span class="cs1-format">(PDF)</span>. Huawei. Archived from <a rel="nofollow" class="external text" href="http://meetings.apnic.net/__data/assets/pdf_file/0012/32007/APRICOT_SPB_Overview.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 15 May 2013<span class="reference-accessdate">. Retrieved <span class="nowrap">11 May</span> 2012</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Shortest+Path+Bridging+IEEE+802.1aq+Overview&amp;rft.pub=Huawei&amp;rft.date=2011-02-24&amp;rft.au=Peter+Ashwood-Smith&amp;rft_id=http%3A%2F%2Fmeetings.apnic.net%2F&#95;_data%2Fassets%2Fpdf_file%2F0012%2F32007%2FAPRICOT_SPB_Overview.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text">
<cite id="CITEREFJim_Duffy2012" class="citation web cs1">Jim Duffy (11 May 2012). <a rel="nofollow" class="external text" href="http://www.pcadvisor.co.uk/news/internet/3357242/largest-illinois-healthcare-system-uproots-cisco-build-40m-private-cloud/">"Largest Illinois healthcare system uproots Cisco to build $40M private cloud"</a>. PC Advisor<span class="reference-accessdate">. Retrieved <span class="nowrap">11 May</span> 2012</span>. <q>Shortest Path Bridging will replace Spanning Tree in the Ethernet fabric.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Largest+Illinois+healthcare+system+uproots+Cisco+to+build+%2440M+private+cloud&amp;rft.pub=PC+Advisor&amp;rft.date=2012-05-11&amp;rft.au=Jim+Duffy&amp;rft_id=http%3A%2F%2Fwww.pcadvisor.co.uk%2Fnews%2Finternet%2F3357242%2Flargest-illinois-healthcare-system-uproots-cisco-build-40m-private-cloud%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-IEEE-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-IEEE_20-0">^</a></b></span> <span class="reference-text">
<cite class="citation news cs1"><a rel="nofollow" class="external text" href="http://www.techpowerup.com/165594/IEEE-Approves-New-IEEE-802.1aq-Shortest-Path-Bridging-Standard.html">"IEEE Approves New IEEE 802.1aq Shortest Path Bridging Standard"</a>. Tech Power Up. 7 May 2012<span class="reference-accessdate">. Retrieved <span class="nowrap">11 May</span> 2012</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IEEE+Approves+New+IEEE+802.1aq+Shortest+Path+Bridging+Standard&amp;rft.date=2012-05-07&amp;rft_id=http%3A%2F%2Fwww.techpowerup.com%2F165594%2FIEEE-Approves-New-IEEE-802.1aq-Shortest-Path-Bridging-Standard.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALoad+balancing+%28computing%29" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text">Mohammad Noormohammadpour, Cauligi S. Raghavendra <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/323723167_Minimizing_Flow_Completion_Times_using_Adaptive_Routing_over_Inter-Datacenter_Wide_Area_Networks">Minimizing Flow Completion Times using Adaptive Routing over Inter-Datacenter Wide Area Networks</a> <i>IEEE INFOCOM 2018 Poster Sessions, DOI:10.13140/RG.2.2.36009.90720</i> 6 January 2019</span>
</li>
<li id="cite_note-architecture-22"><span class="mw-cite-backlink">^ <a href="#cite_ref-architecture_22-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-architecture_22-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">M. Noormohammadpour, C. S. Raghavendra, <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/321744877_Datacenter_Traffic_Control_Understanding_Techniques_and_Trade-offs">"Datacenter Traffic Control: Understanding Techniques and Trade-offs,"</a> IEEE Communications Surveys &amp; Tutorials, vol. PP, no. 99, pp. 1-1.</span>
</li>
<li id="cite_note-IBM-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-IBM_23-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.ibm.com/support/knowledgecenter/en/SSVJJU_6.4.0/com.ibm.IBMDS.doc_6.4/ds_ag_srv_adm_dd_failover_load_balancing.html">Failover and load balancing</a> <i>IBM</i> 6 January 2019</span>
</li>
</ol></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Load_balancing_(computing)&amp;action=edit&amp;section=41" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table role="presentation" class="mbox-small plainlinks sistersitebox" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png" decoding="async" width="30" height="40" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/45px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/59px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376" /></td>
<td class="mbox-text plainlist">Wikimedia Commons has media related to <i><b><a href="https://commons.wikimedia.org/wiki/Category:Load_balancing_(computing)" class="extiw" title="commons:Category:Load balancing (computing)"><span style="">Load balancing (computing)</span></a></b></i>.</td></tr>
</tbody></table>
<ul><li><a rel="nofollow" class="external text" href="http://www.udaparts.com/document/articles/snpisec.htm">Server routing for load balancing with full auto failure recovery</a></li></ul>
<div role="navigation" class="navbox authority-control" aria-labelledby="Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q575614#identifiers&amp;#124;Edit_this_at_Wikidata" style="padding:3px"><table class="nowraplinks hlist navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th id="Authority_control_frameless_&amp;#124;text-top_&amp;#124;10px_&amp;#124;alt=Edit_this_at_Wikidata_&amp;#124;link=https&amp;#58;//www.wikidata.org/wiki/Q575614#identifiers&amp;#124;Edit_this_at_Wikidata" scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Help:Authority_control" title="Help:Authority control">Authority control</a> <a href="https://www.wikidata.org/wiki/Q575614#identifiers" title="Edit this at Wikidata"><img alt="Edit this at Wikidata" src="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png" decoding="async" width="10" height="10" style="vertical-align: text-top" srcset="//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x" data-file-width="20" data-file-height="20" /></a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><span class="nowrap"><a href="/wiki/GND_(identifier)" class="mw-redirect" title="GND (identifier)">GND</a>: <span class="uid"><a rel="nofollow" class="external text" href="https://d-nb.info/gnd/4323960-2">4323960-2</a></span></span></li></ul>
</div></td></tr></tbody></table></div>
